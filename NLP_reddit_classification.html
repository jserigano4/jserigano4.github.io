<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>NLP Reddit Classification</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<section id="header">
					<header>
						<span class="image avatar"><img src="images/Serigano-Joseph.jpeg" alt="" /></span>
						<h1 id="logo"><a href="#">Joseph Serigano, Ph.D.</a></h1>
						<p>Data Scientist<br />
						<p>Python | SQL | MATLAB <br />
	
						</p>
					</header>
					<footer>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/joseph-serigano/" class="icon brands fa-linkedin alt"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/jserigano4" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
							<li><a href="mailto:jserigano4@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
							<li><a href="https://jserigano4.github.io/Serigano_resume.pdf"><span class="far fa-file-pdf"> Resume</span></a></li>
						</ul>
					</footer>
				</section>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<h2>NLP Reddit Classification</h2>
								<p>More detailed information, including code and further analysis, can be found on my <a href="https://github.com/jserigano4/NLP_reddit_classification">Github</a> and slides for a presentation on this project can be found <a href="https://github.com/jserigano4/NLP_reddit_classification/blob/main/NLP_reddit_classification_Serigano.pdf">here</a>.</p>
								<h2>Introduction</h2>
								<p>Reddit is a social network of threads organized by subject and separated by interests. Users can post to these individual subreddits and interact with other members who share similar interests. The popularity of Reddit 
									means there is a wealth of data that continues to grow daily, making it the perfect platform to aggregate data and analyze these data sets to note trends or make predictions. The ability to predict the subreddit from which 
									a post originated is an example of a classification model that could be useful to members of the Reddit team who are responsible for the website's oversight.</p>

								<p><b>The goal of this project is to create an NLP model that accurately predicts from which subreddit a given post originated. </b>This will be done by collecting posts from the subreddits 
									<a href="https://www.reddit.com/r/LifeProTips/">r/LifeProTips</a> and <a href="https://www.reddit.com/r/ShittyLifeProTips/">r/ShittyLifeProTips</a> and classify these posts based on their content. These subreddits include tips that can be used to improve one's life or, on the other hand, "tips" that mock the idea.
									r/LifeProTips is full of helpful advice from reddit users, while r/ShittyLifeProTips is full of content and advice that simply doesn't make sense. <b> So, can we use NLP to discern a good/helpful tip from a bad one, and
									can we use NLP to detect sarcasm and flag it as unhelpful advice?</b>							

								<h2>Executive Summary</h2>
								<p>The data for this project was collected from each subreddit through <a href="https://github.com/pushshift/api">Pushift</a>'s API. In order to create a robust model, approximately 10,000 posts from each subreddit were used for classification. Pushshift scrapes 
									a lot of information for each post, however posts to these specific subreddits contain the bulk of their message in the post's title. For this reason, the only data we save for analysis are the subreddit name and the 
									title of each post. The data, including original subreddit, original title post, word count of original title post, and cleaned title post (without stop words) can be found on <a href="https://github.com/jserigano4/NLP_reddit_classification">Github</a>.</p>
									
								<p>The goal is to build a classification model that can determine from which subreddit a post originated, however preliminary analysis shows that our subreddit posts are very similar to one another.
									The average word count is 19 words per title for both subreddits.
								</p>
								<style>
									.imgStyle {
										height: 100%;
										width: 100%;
									}
									</style>
									<html>
									<div class="mydiv">
									<img src="images/word_count.png" class="imgStyle" />
									</div>

								<p>These subreddits also share a lot of the most common bigrams as well.</p>

								<style>
									.imgStyle {
										height: 100%;
										width: 100%;
									}
									</style>
									<html>
									<div class="mydiv">
									<img src="images/LifeProTips_cleaned.png" class="imgStyle" />
									</div>

									<style>
										.imgStyle {
											height: 100%;
											width: 100%;
										}
										</style>
										<html>
										<div class="mydiv">
										<img src="images/ShittyLifeProTips_cleaned.png" class="imgStyle" />
										</div>

								<p>Multiple classification models were then developed in order to determine which variation of vectorizer and classifier produced the most accurate model predictions.

								<p>The vectorizers included: CountVectorizer() and TfidfVectorizer().</p>
								<p>The classifiers included: LogisticRegression(), KNeighborsClassifier(),
									MultinomialNB(),
									RandomForestClassifier(),
									AdaBoostClassifier(),
									GradientBoostingClassifier().</p>
								<p>All together, 12 different combinations were evaluated along with a parameter search for each model. In the end, a Logistic Regression model with L2 (Ridge) regularization and TfidfVectorizer with 
									no preprocessing of the titles (i.e., no lemmatizing or stemming of words) performed best. This model accurately predicted the subreddit classification of 75.7% of the test data based on our input
									 features. It should be noted that the scores for our next best-fitting models are very similar to the best model. These models are a Multinomial Naive Bayes model with TfidfVectorizer and another 
									 Logistic Regression model with L2 regularization and CountVectorizer. Additionally, all models tested here outperformed the baseline null model (50.4% accuracy), and train and test scores for each
									model were very similar, indicating that the models were not overfit.
									</p>
									An accuracy of 75.7% is not very high but this is also not very surprising. As noted earlier, these data sets were very similar to each other, right down to the average word count per title, 
									and these data sets also had very similar word usage. With no discerning qualitites to either data set, an accuracy of 75.7% is perhaps as high as one can achieve. 
								</p>

							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; 2022 Joseph Serigano. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
